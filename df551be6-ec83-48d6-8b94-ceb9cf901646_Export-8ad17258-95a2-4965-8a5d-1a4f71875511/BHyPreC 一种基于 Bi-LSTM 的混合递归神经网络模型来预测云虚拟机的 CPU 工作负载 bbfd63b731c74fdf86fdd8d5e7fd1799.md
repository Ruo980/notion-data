# BHyPreC:一种基于 Bi-LSTM 的混合递归神经网络模型来预测云虚拟机的 CPU 工作负载

## 摘要

---

随着云计算技术的进步，对云资源最大化利用的需求越来越大。它增加了云系统的计算功耗。云虚拟机（VM）的整合为降低云数据中心（DC）的能耗提供了一种实用的方法。通过根据云的未来工作负载预测做出主动决策，可以在不违反服务级别协议（SLA）的情况下实现有效的虚拟机整合和虚拟机迁移。有效的任务调度是云计算的另一个主要问题，它也依赖于对资源使用情况的准确预测。云工作负载跟踪表现出周期性和非周期性模式，负载峰值突然出现。

本文提出了一个基于混合递归神经网络（RNN）的预测模型，名为BHyPreC。BHyPreC 架构包括位于堆叠式长短期内存 (LSTM) 和门控循环单元 (GRU) 之上的双向长短期内存 (Bi-LSTM)。BHyPreC用于预测云虚拟机未来的CPU使用工作负载。与其他统计模型相比。本文提出的模型分别增强了Bi-LSTM、LSTM和GRU模型的非线性数据分析能力，并表现出更好的准确性。

文章的最后，观察历史窗口大小和训练测试数据大小的变化对这些模型的影响。实验结果表明，与自回归积分移动平均 (ARIMA)、LSTM、GRU 和 Bi-LSTM 模型相比，模型在短期提前和长期提前预测方面具有更高的准确性和更好的性能。

## 现有问题

---

在峰值负载到达期间，虚拟机资源的总需求超过了服务器的可用资源容量，导致服务器过载和性能下降，例如，一些虚拟机可能会崩溃、资源不可用时间延长和响应时间增加等。而资源需求不足会导致计算资源的浪费。为了管理资源容量的动态和随机需求或处理过载/欠载，虚拟机从过载/欠负载的服务器实时迁移到具有足够资源容量的另一台服务器，会导致执行延迟。（为什么需要进行负载预测）

借助精确的预测，可以在利用云资源和执行任务方面取得巨大进步。有效预测工作量是使系统能够做出主动和动态决策的关键，而不是被动决策。虚拟机（VM）的整合可以通过将VM合并并重新分配到少量活动物理服务器中来实现。（负载预测的重要性）

负载预测是时间序列预测的一种。在云和网格系统中提供精确的未来工作负载预测一直是一项艰巨的挑战，因为各种时间序列数据有时具有不同的模式和突然的峰值。一种算法很可能在一个时间序列内产生不同的欠预测和过预测。因此，使用这种预测的结果设计方法变得困难。现有的预测实践涉及使用统计模型和神经网络的传统预测方法。然而，在与时间序列预测相互作用时，所有方法都存在一些不足。具有突然峰值的云资源的重复工作负载模式在进行准确预测方面起着关键作用。（负载预测主要涉及哪类为题）

在处理时间序列预测的各种模型中，一个常见的模型是统计模型。（时间序列预测的各种模型比较——说明深度学习的优势）

统计预测包括使用统计数据来预测未来会发生什么，这取决于历史证据。对于复杂和非线性的时间序列预测，统计方法效率低且不可靠。自回归（AR）、移动平均（MA）、自回归移动平均（ARMA）、自退化综合移动平均（ARIMA）、简单指数平滑（SES）、Holt-Winters指数平滑（HWES）等都是基于统计学的经典时间序列预测方法的例子。

此外，还可以使用神经网络来预测工作量。与统计方法相比，神经网络模型在处理复杂观测方面表现更好。

不均匀的时间结构、不完整的值、过度的噪声以及几个变量之间复杂的相互关系是真实世界时间序列数据的特征。此外，数据的时间结构中存在的趋势和季节性使预测任务更加困难。深度学习技术可以处理这些问题，因为它们可以自动学习并从原始和错误数据中提取特征。

因此，深度学习技术对于时间序列数据预测的重要性是巨大的，比如云数据中心的CPU负载。

门控递归单元（GRU）和长短期存储器（LSTM）是常用的RNN。由于其处理非线性数据的独创性，基于RNN的模型被用于各种时间序列预测应用，例如云工作量预测、股票预测[17]–[19]和天气预测[20]等。多种方法的有效组合可以产生混合模型。（采用深度学习混合模型预测的优势）

在本文中，提出了一种新的混合模型来预测重要的云数据中心资源使用情况，即虚拟机中的中央处理器（CPU）使用情况。

## 主要工作

---

文章主要做了以下工作：

提出了一种新的混合模型，即BHyPreC。它将1维卷积层、双向长短期存储器（Bi-LSTM）、LSTM和GRU与最佳超参数设置相结合，以准确预测多步前工作负载。模型能够有效地提取特征，并使用过去和未来的数据来学习工作负载模式的性质，以及精心设计的堆叠LSTM和GRU单元的组合；使模型在处理非线性和复杂的数据模式方面占据了上风。

应用历史窗口大小和训练：测试比率的组合网格搜索技术来适当地调整模型，并获得窗口大小和培训：测试比率大小的最佳集合。此集合负责在预测虚拟机中的CPU使用情况时生成最小的错误。

在整个训练数据中实现了一种重叠滑动窗口方法。结果，数据被分割成相等长度的段。然后将分段数据输入到我们模型的1D卷积层中。这有助于提高长期预测的准确性。

针对四种不同的评估指标来评估BHyPreC模型。实验结果证实了BHyPreC模型与传统ARIMA和用相同数据集训练的其他三个流行的基于RNN的模型相比的优越性。

对于上面所提到的每一种模型，分别对每个评估指标进行累积分布函数（CDF）、盒图、预测长度和误差百分比上升分析。这是通过一系列系统分析完成的。对于每个分析，通过使用网格搜索窗口大小和训练测试比的最佳集合训练模型来获得最小值

## 文章结构

---

按以下方式安排了论文的其余部分。第二节讨论了相关工作。第三节展示了我们提出的模型的完整架构。第四节展示了用于评估的实验结果的分析和度量。在第五节中，我们对全文进行了总结和总结，并提出了未来的研究方向。

## 前瞻知识

---

RNN（循环神经网络）是一种神经网络架构，它可以处理序列数据，例如时间序列或文本序列。RNN的主要特点是它可以使用先前的状态来影响当前状态，这使得它能够捕捉到序列数据中的时间依赖性。然而，RNN存在梯度消失和短期记忆问题，这是由于反向传播算法在时间上反复应用时，导致梯度逐渐消失或爆炸。这使得RNN难以学习长期依赖关系，因为它们只能记住最近的状态。

LSTM（长短期记忆网络） 作为一种改进的 RNN，其继承了 RNN 模型的优点，并且利用独特的门结构有效解决了 RNN中的梯度消失和短期记忆问题。LSTM引入了门控机制，包括更新门、遗忘门和输出门，以控制信息的流动和记忆的更新。这使得LSTM能够更好地捕捉长期依赖关系，相较 RNN 和GRU，LSTM 模型的拟合和预测精度总体较高，但是，由于 LSTM 参数过多导致其训练过程耗时较长。

GRU（门控循环单元） 作为 LSTM 的一种变体，也可以有效地解决 RNN 中的梯度爆炸和梯度消失问题。与 LSTM相比，GRU 的结构更为简单，其将遗忘门和输入门合并为一个更新门。由于 GRU 减少了一个门，矩阵乘法变少，因此当训练数据量很大时可以节省大量的时间。

Bi-LSTM是双向长短期记忆网络（Bidirectional Long Short-Term Memory Network）的缩写。它是一种循环神经网络（RNN）的变体，用于处理序列数据。

传统的LSTM网络在处理序列数据时只考虑了过去的上下文信息，而Bi-LSTM则同时考虑了过去和未来的上下文信息。它由两个LSTM组成，一个按照正向顺序处理输入序列，另一个按照逆向顺序处理输入序列。这样，Bi-LSTM能够同时捕捉到过去和未来的依赖关系。

在Bi-LSTM中，正向LSTM和逆向LSTM的隐藏状态会被连接起来，形成一个更丰富的表示。这种双向的信息流动使得Bi-LSTM在处理序列数据时能够更好地理解上下文，并且能够更好地捕捉长期依赖关系。

## 模型结构

---

本节说明并描述了本文采用的整个程序。它被细分为七个子部分。第III-A小节总结了我们提出的模型：BHyPreC及其可视化。模型的核心概念：神经网络和递归神经网络的概述分别在第III-B小节和第III-C小节中阐述。然后，在第III-D、III-E和III-F小节中分别简要介绍了我们模型中提出的三个关键RNN单元，即LSTM、GRU和Bi-LSTM。在第III-G小节中，还对我们模型的训练时间复杂性进行了关键讨论。

### 拟定架构

![Untitled](BHyPreC%20%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%20Bi-LSTM%20%E7%9A%84%E6%B7%B7%E5%90%88%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%9D%A5%E9%A2%84%E6%B5%8B%E4%BA%91%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%20CPU%20%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%20bbfd63b731c74fdf86fdd8d5e7fd1799/Untitled.png)

在这里，输入数据最初使用“MinMaxScalar”函数进行预处理。该函数允许我们将输入数据（CPU使用率）归一化到 0 到 1 的范围内（归一化处理）。然后，通过实现滑动窗口方法将归一化的数据输入到一维卷积神经网络 (CNN) 层。1维 CNN非常适用于从较大数据集的固定长度部分中提取特征，其中特征在该部分中的位置不太相关。它在时间序列分析中非常有用。
这个1维 CNN层包含64个输出滤波器，内核大小为5，步长为1，激活函数“relu”。

这个CNN层的输出然后被输入到一个Bi-LSTM层中，该层具有128个隐藏记忆单元，结合了前向和后向传播。Bi-LSTM的输出然后通过2个连续的LSTM层和一个GRU层。每个层都包含64个隐藏记忆单元。然后，输出将被传递到一个包含50个隐藏记忆单元的LSTM层中。最后，输出将通过一个包含1层的全连接神经网络进行传播。在这里，Bi-LSTM使用前向和后向信息以双向方式更新隐藏状态。BHyPreC模型的最后一部分结合了一个具有单个输出层神经元的全连接密集神经网络来计算最终预测。

同样，LSTM和GRU是RNN的两个特殊变体，与Bi-LSTM相比具有更少的参数。

虽然LSTM通常在大型数据集中表现更好，而GRU在小型数据集中表现更好；但是，将两种RNN单元进行良好平衡的组合，并调整超参数，可以获得更好的结果。输入时间序列数据被分割成连续的历史序列，每个序列由固定大小的数据组成，每个序列后面跟着一个定义大小的预测序列。所提出的架构将历史和预测序列作为输入和监督输出/标签。

上面所提出的BhyPreC模型的摘要如表2所示。这里，“HWS”表示历史窗口大小。对于这个实验，我们在网格搜索方法中依次取30、60、90和120的HWS。这里，“Dense”层表示完全连接的神经网络。

![Untitled](BHyPreC%20%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%20Bi-LSTM%20%E7%9A%84%E6%B7%B7%E5%90%88%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%9D%A5%E9%A2%84%E6%B5%8B%E4%BA%91%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%20CPU%20%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%20bbfd63b731c74fdf86fdd8d5e7fd1799/Untitled%201.png)

在我们的BHyPreC模型中，总共有196875个可训练参数。表3显示了在我们提出的BHyPreC模型中使用的超参数。我们的模型中使用的每个RNN单元的批大小、卷积滤波器大小、内核大小和输出神经元层都是通过严格的试错方法进行调整的。Adam优化器的学习率β1、β2和根据[38]设置。我们对每个模型进行了100次迭代。

### RNN

RNN是一种特殊类型的人工神经网络算法，适用于处理顺序性数据，例如时间序列数据。RNN配备有反馈环路，可以利用其内部状态或记忆处理可变长度的输入序列。在这种情况下，从第n-1步的输出被反馈回网络，以利用第n步的结果，以此类推，对于每个后续步骤都是如此。这种网络结构可以用于我们的云工作负载预测角色，通过基于先前负载值预测下一个值。下图展示了一个具有分散形状的隐藏层的RNN模型，其中Xt是时间t的输入数据，Ht是该时间步的隐藏状态，Yt是RNN的输出。

![Untitled](BHyPreC%20%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%20Bi-LSTM%20%E7%9A%84%E6%B7%B7%E5%90%88%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%9D%A5%E9%A2%84%E6%B5%8B%E4%BA%91%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%20CPU%20%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%20bbfd63b731c74fdf86fdd8d5e7fd1799/Untitled%202.png)

从图3中可以看出，RNN的隐藏状态Ht取决于以前的隐藏状态值和当前的时间步长输出。与典型的深度神经网络不同，RNN在所有阶段都使用相同的参数矩阵和向量阵列。它显著减少了RNN需要学习的参数数量。

### LSTM

由于时间反向传播技术，梯度消失和短期记忆问题在RNN中最为普遍。这个问题可以通过使用一种特殊的RNN来解决，称为LSTM。它也擅长学习长期依赖关系。图4显示了LSTM单元的概述。

LSTM单元有三个门，即输入门、遗忘门和输出门。所有门都具有sigmoid激活函数，作为过滤器决定哪些信息要保留，哪些要遗忘。除了门，LSTM还具有以下组件[47]：

![Untitled](BHyPreC%20%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%20Bi-LSTM%20%E7%9A%84%E6%B7%B7%E5%90%88%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%9D%A5%E9%A2%84%E6%B5%8B%E4%BA%91%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%20CPU%20%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%20bbfd63b731c74fdf86fdd8d5e7fd1799/Untitled%203.png)

- Xt是时间步t的输入数据。
• Ht-1是时间步t-1的隐藏状态，或来自上一个时间步。它在LSTM中作为短期记忆。
• Ct-1是时间步t-1的单元状态。它在LSTM中负责长期记忆。它在LSTM内部的两个点上进行更新。
• σ是sigmoid激活函数。
• tanh是激活函数，其输出范围为1到-1。
• ft是遗忘门的sigmoid函数的输出，它决定是否遗忘或记住上一个时间步的记忆Ct-1。
• it是输入sigmoid门的输出，它控制要添加到单元状态的新输入数据信息。
• c~t是候选单元状态，是使用tanh对外部输入数据Xt进行非线性变换的结果。

### GRU

GRU是带有门控机制的RNN的高级版本。它能够防止传统RNN中出现的梯度消失问题。它与LSTM相比具有更少的训练参数，因此速度更快，训练时间更短，内存消耗更少。不需要任何控制，它会公开所有的隐藏状态。对于较短的输入数据序列，GRU是RNN的更适合版本。下图显示了GRU单元的架构。

![Untitled](BHyPreC%20%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%20Bi-LSTM%20%E7%9A%84%E6%B7%B7%E5%90%88%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%9D%A5%E9%A2%84%E6%B5%8B%E4%BA%91%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%20CPU%20%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%20bbfd63b731c74fdf86fdd8d5e7fd1799/Untitled%204.png)

与LSTM不同，GRU有两个门，即重置门和更新门。更新门结合了LSTM的遗忘门和输入门的功能。它帮助模型确定多少先前的数据（来自之前的时间步）可以移动到未来。另一方面，重置门用于确定可以删除多少来自过去的数据。GRU还删除了LSTM中存在的单元状态，并将数据传输到隐藏状态。

### Bi-LSTM

Bi-LSTM是RNN的一种独特变体，由两个LSTM层组合在一起。其中一个LSTM单元在正向方向处理输入，另一个单元在反向方向处理输入。它是传统LSTM的扩展，可以保留过去和未来的信息。这导致网络可以访问大量的信息，从而更好地理解上下文。下图显示了Bi-LSTM网络的块图。下图中显示的每个LSTM块都遵循III-D小节中介绍的内部机制。

![Untitled](BHyPreC%20%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%20Bi-LSTM%20%E7%9A%84%E6%B7%B7%E5%90%88%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%9D%A5%E9%A2%84%E6%B5%8B%E4%BA%91%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%20CPU%20%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%20bbfd63b731c74fdf86fdd8d5e7fd1799/Untitled%205.png)

## 结果分析

---

结果分析部分分为九个小节，用于描述了要训练的数据集，简要叙述了评估指标，说明了我们提出的模型的详细实验结果，并将我们的模型与其他相关预测模型的性能进行了比较，同时进行了适当的统计测试。本节还演示了所有模型在预测长度变化的情况下的性能比较。

### 数据集描述和预处理

在这项工作中，一个通常被称为Bitbrain的分布式数据中心被用于收集大规模和长期的真实数据痕迹。该数据集包括来自Bitbrains的分布式DC的1750台虚拟机的性能指标，该DC专门为企业提供受控托管和商业计算。它使用通用的VMware资源调配框架（如动态资源调度和存储动态资源调度）来管理计算能力。

每个文件都包括虚拟机性能指标。这些文件按轨道分组：fastStorage和Rnd。FastStorage由1250个隶属于SAN存储设备的虚拟机组成，Rnd由500个隶属于更快的存储区域网络（SAN）或相对较慢的网络连接存储（NAS）设备的虚拟主机组成。每个文件的布局是基于行的，每一行都反映了对包含11列的性能指标的观察。该数据集总共包含5446811个CPU小时的数据，具有23214 GB内存和5501个内核。

CPU使用数据使用“MinMaxScaler”函数在0到1的范围内进行归一化。下图显示了43155分钟内的CPU使用值。这里，数据是在连续的5分钟时间窗口内采样的。因此，下图中X轴上连续两点之间的时间间隔为5分钟。

### 评估指标

为了精确评估我们模型的预测准确性，我们分析了各种评估指标，例如均方误差（MSE）、均方根误差（RMSE）、平均绝对误差（MAE）和平均绝对百分比误差（MAPE）。每个评估指标都反映了模型的性能。在这里，较低的指标值表示更好的预测准确性。

估计器的原始序列和预测序列之间的平方差的平均值由MSE表示：

![Untitled](BHyPreC%20%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%20Bi-LSTM%20%E7%9A%84%E6%B7%B7%E5%90%88%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%9D%A5%E9%A2%84%E6%B5%8B%E4%BA%91%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%20CPU%20%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%20bbfd63b731c74fdf86fdd8d5e7fd1799/Untitled%206.png)

RMSE（均方根误差）是一种常用的评估指标，它衡量了初始序列和期望序列之间平方差的平均值的平方根。它的定义如下：

![Untitled](BHyPreC%20%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%20Bi-LSTM%20%E7%9A%84%E6%B7%B7%E5%90%88%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%9D%A5%E9%A2%84%E6%B5%8B%E4%BA%91%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%20CPU%20%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%20bbfd63b731c74fdf86fdd8d5e7fd1799/Untitled%207.png)

用于时间序列数据中预测的一个非常常用的度量是MAE。它是原始值和预测值之间的平均差：

![Untitled](BHyPreC%20%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%20Bi-LSTM%20%E7%9A%84%E6%B7%B7%E5%90%88%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%9D%A5%E9%A2%84%E6%B5%8B%E4%BA%91%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%20CPU%20%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%20bbfd63b731c74fdf86fdd8d5e7fd1799/Untitled%208.png)

MAPE是用于评估预测模型的预测精度的另一种有效工具。它被定义为：

![Untitled](BHyPreC%20%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%20Bi-LSTM%20%E7%9A%84%E6%B7%B7%E5%90%88%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%9D%A5%E9%A2%84%E6%B5%8B%E4%BA%91%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%20CPU%20%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%20bbfd63b731c74fdf86fdd8d5e7fd1799/Untitled%209.png)

### 最佳窗口和数据分割大小分析

本节的目的是获取最佳窗口和数据分割的最佳值。

前面我们提到测试使用了30、60、90和120的HWS历史窗口值。为了获得最佳的历史窗口大小，我们针对四种不同的窗口宽度（30，60，90，120）训练了我们的模型。对于每个独特的窗口大小，我们将数据集划分为四个训练测试划分比率。

总共，我们获得了一组窗口大小和数据分割率的16种不同组合:

![Untitled](BHyPreC%20%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%20Bi-LSTM%20%E7%9A%84%E6%B7%B7%E5%90%88%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%9D%A5%E9%A2%84%E6%B5%8B%E4%BA%91%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%20CPU%20%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%20bbfd63b731c74fdf86fdd8d5e7fd1799/Untitled%2010.png)

最初，所提出的模型是使用上述16种不同组合的“均方误差”损失函数编译的。我们评估了这些训练模型的性能，并计算了MSE和RMSE。同样，对于每组16个独特的组合，我们使用“平均绝对误差”和“平均绝对百分比误差”损失函数编译我们的模型，并分别计算MAE和MAPE用于模型评估。

我们总共提出的模型针对36个独特的组合进行了训练。结果，我们获得了48个不同的误差值。

LSTM、GRU和Bi-LSTM基于深度学习技术，需要历史窗口大小来训练数据集。为了执行上述实验，我们在python中使用了Keras和TensorFlow库后端。我们选择了谷歌合作平台来训练我们的所有模型，并使用Adam优化器来确定编译模型的最佳学习率。对于每个训练和验证，我们使用64的批量大小和100的历元大小。

我们的模型不仅优于经典模型，而且与本工作中研究的其他相关深度学习方法相比，性能也要好得多。我们的混合模型比所有其他基于RNN的模型都有最好的组合，其误差最小化幅度非常高。

### 稳定性分析

![Untitled](BHyPreC%20%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%20Bi-LSTM%20%E7%9A%84%E6%B7%B7%E5%90%88%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%9D%A5%E9%A2%84%E6%B5%8B%E4%BA%91%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%20CPU%20%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%20bbfd63b731c74fdf86fdd8d5e7fd1799/Untitled%2011.png)

### 误差分布分析

![Untitled](BHyPreC%20%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%20Bi-LSTM%20%E7%9A%84%E6%B7%B7%E5%90%88%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%9D%A5%E9%A2%84%E6%B5%8B%E4%BA%91%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%20CPU%20%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%20bbfd63b731c74fdf86fdd8d5e7fd1799/Untitled%2012.png)

### 预测长度分析

> **预测长度/步骤（forecasting step）：**在机器学习中，forecasting step通常指的是预测模型在时间序列数据中向前预测的步数。例如，如果我们正在使用时间序列数据来预测未来一周的销售额，并且我们希望预测未来7天的销售额，则每一天都是一个forecasting step。在时间序列分析中，forecasting step通常是一个重要的参数，因为它可以影响预测模型的准确性和稳定性。较短的forecasting step可以提高模型的灵敏度，但可能会导致过拟合，而较长的forecasting step可以提高模型的稳定性，但可能会降低模型的准确性。因此，在选择forecasting step时需要进行权衡和调整，以获得最佳的预测结果。
> 

预测模型性能随着预测步骤增加的分析也是关键的绩效指标。对于多步骤工作负载预测来说，能够在大的预测步骤中给出较小的预测误差的模型更加适用。了解精确的未来工作负载模式将为我们在虚拟机迁移和整合任务中提供优势，而不会违反服务级别协议。这也将使我们能够进行有效的任务调度，并通过适当的云资源分配和利用来确保降低能源消耗。

下图描绘了预测长度或步长对每个评估指标的不同预测模型的影响。这里，每个连续预测步骤之间的间隔为5分钟。因此，与预测步骤“1200”对应的错误表示CPU使用工作负载预测错误提前“100小时”。在整个预测长度中给出最小误差量并且由于预测步长的变化而表现出最小误差的模型最适合于多步预测。

图11清楚地表明，误差随着预测步骤的增加而增加。从图11a和11b中，我们可以看到，对于LSTM、GRU和ARIMA模型，MSE和RMSE值分别随着预测长度的增加而增加。

在Bi-LSTM和我们提出的模型的情况下，由于它们能够通过学习过去和未来的工作负载模式变化来提取时间特征，因此预测误差的增加率很小

![Untitled](BHyPreC%20%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%20Bi-LSTM%20%E7%9A%84%E6%B7%B7%E5%90%88%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%9D%A5%E9%A2%84%E6%B5%8B%E4%BA%91%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%20CPU%20%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%20bbfd63b731c74fdf86fdd8d5e7fd1799/Untitled%2013.png)

此后，ARIMA和BICC平滑滤波器模型被证明是最不适合多步预测的。

分析图11c和图11d，我们可以说，我们的模型在预测未来CPU使用时产生的误差最小，ARIMA的性能最差。在ARIMA和BIC C平滑滤波器模型的情况下，与RNN和混合模型相比，MAPE的裕度对于未来的提前预测要高得多。同样，随着预测长度的增加，ARIMA中的MAE显著增加。在这两种情况下，我们的模型都可以以最小的误差进行精确的预测。在我们的模型的情况下，预测长度变化的影响也是最小的。在图11所示的上述每个场景中，通过为时间提前预测生成最小的误差，我们的模型似乎是多步提前预测的最合适的候选者。

### 多步预测

我们提出的混合模型不仅可以准确地预测单步预测，而且可以准确地预见CPU使用模式的长期变化。图12显示了长期CPU使用预测时间序列曲线以及实际CPU使用工作负载曲线。这里，间隔长度为5分钟。下图分别是提前6小时、提前1天、提前3天、提前5天的预测负载曲线：

![Untitled](BHyPreC%20%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%20Bi-LSTM%20%E7%9A%84%E6%B7%B7%E5%90%88%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%9D%A5%E9%A2%84%E6%B5%8B%E4%BA%91%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%20CPU%20%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%20bbfd63b731c74fdf86fdd8d5e7fd1799/Untitled%2014.png)

提前六个小时进行的预测结果如图所示。12a清楚地展示了我们的模型准确识别突然工作量峰值的能力。在这里预测负载曲线几乎与实际CPU使用曲线一致，具有非常小的偏差和轻微阻尼的峰值幅度值。

如图12b、图12c和图12d所示的提前1天、3天和5天的预测也分别证明了我们的模型在多步提前预测中的适用性。在每种情况下，尽管预测窗口很长，但两条曲线都相互重合。

它表明，我们的模型能够进行精确的预测，并且受预测窗口范围的影响很小。

我们的模型被证明是最适合长期预测未来工作负载的模型。